{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2: Representación de Texto y Motores de Búsqueda\n",
    "\n",
    "En esta tarea vamos a ver cómo implementar un motor de búsqueda básico utilizando técnicas de representación de texto y medidas de similitud. Vamos a aprender a usar algunas funciones simples de las librerías scikit-learn y pandas.\n",
    "\n",
    "Primero, vamos a importar algunas librerías que necesitaremos antes de seguir adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sns as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Tf-idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split  # Hablaremos más sobre validación y selección de modelos después.\n",
    "from sklearn.naive_bayes import MultinomialNB  # Un clasificador simple, no hemos visto cómo funciona esto en clases.\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí te dejo una función de utilidad. Se utiliza para ordenar un arreglo numpy por su columna n-ésima (por defecto, ordena por la primera columna con n = 0). Devuelve los resultados en orden descendente. No es necesario que modifiques esta función, y no es obligatorio que la uses si no quieres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T14:54:28.339526300Z",
     "start_time": "2023-09-04T14:54:28.303200Z"
    }
   },
   "outputs": [],
   "source": [
    "def sort_array_col(arr, n=0):\n",
    "    return arr[arr[:,n].argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leyendo los datos\n",
    "\n",
    "Tenemos un conjunto de resúmenes de artículos en un archivo CSV de tres temas diferentes (bioinformática, procesamiento de datos, redes). Tu primera tarea es leer el archivo CSV y extraer los artículos. Nos interesa solamente los resúmenes y el tema de cada artículo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV 02_Dataset.csv con Pandas.\n",
    "data = pd.read_csv(\"02_Dataset.csv\")\n",
    "\n",
    "# Convertir el tema en una variable numérica (pista: usar el llamado de función data.topic.map). \n",
    "# Asignar 0 a 'bioinformatics', 1 a 'network' y 2 a 'preprocessing data'.\n",
    "data['topic_num'] = data['topic'].map({'bioinformatics': 0, 'network': 1, 'preprocessing data': 2})\n",
    "\n",
    "X = data['abstract'].values\n",
    "y = data['topic_num'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir el conjunto de datos en un conjunto de entrenamiento (que utilizaremos para entrenar los modelos de representación) y un conjunto de pruebas que usaremos más adelante en la última parte de la tarea. Aunque no es estrictamente necesario para la primera parte de esta tarea, es una buena práctica para la segunda parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:04:09.190597200Z",
     "start_time": "2023-09-04T15:04:09.169235200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dividir X e y en conjuntos de entrenamiento y prueba\n",
    "# 70% del conjunto de datos se usa para entrenar los modelos.\n",
    "# En este caso solo utilizaremos este conjunto de datos para la primera parte.\n",
    "# 30% del conjunto de datos se usa para probar los modelos. \n",
    "# Esto se usará para probar el clasificador de la última parte.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Bag of Words (BoW)\n",
    "\n",
    "Ahora construimos el modelo de Bag of Words (BoW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:19:26.369168400Z",
     "start_time": "2023-09-04T15:19:26.252798100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instanciar el vectorizador\n",
    "# Para Bag of Words quieres usar CountVectorizer con los siguientes parámetros: \n",
    "# stop_words='english', ngram_range=(1, 2), max_df=0.9, min_df=2.\n",
    "# Puedes intentar mejorar el rendimiento de tu modelo cambiando los últimos dos parámetros.\n",
    "# Notar que estos modelos son específicos para este problema.\n",
    "# En un problema real, los parámetros serían posiblemente muy diferentes.\n",
    "vect_bow = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.9, min_df=2)\n",
    "# Ajustar el modelo cn X_train.\n",
    "vect_bow.fit(X_train)\n",
    "# Luego, usalo para crear la matriz de documentos y términos.\n",
    "X_train_dtm_bow = vect_bow.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vectorizamos el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:19:47.233045700Z",
     "start_time": "2023-09-04T15:19:47.186952500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformar los datos de prueba (utilizando el vocabulario ajustado) en una matriz documento-término\n",
    "X_test_dtm_bow = vect_bow.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ahora vamos a consultar nuestro modelo! Probaremos el modelo con la cadena de búsqueda proporcionada en los datos de X_train. Siéntete libre de probar con tus propias cadenas, ¡es un ejercicio divertido! :)\n",
    "\n",
    "Debes devolver los elementos ordenados por su similitud (los elementos más similares deben mostrarse primero) y el propio texto debe mostrarse también.\n",
    "\n",
    "Solo debes devolver los elementos que tengan una similitud mayor a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:29:12.596652Z",
     "start_time": "2023-09-04T15:29:12.566719800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento: 2\n",
      "Similitud de coseno: 0.20459830184114206\n",
      "\n",
      "\n",
      "Documento: 3\n",
      "Similitud de coseno: 0.05012547071170855\n",
      "\n",
      "\n",
      "Documento: 4\n",
      "Similitud de coseno: 0.2090605025017727\n",
      "\n",
      "\n",
      "Documento: 5\n",
      "Similitud de coseno: 0.3304093002275449\n",
      "\n",
      "\n",
      "Documento: 7\n",
      "Similitud de coseno: 0.4190581774617469\n",
      "\n",
      "\n",
      "Documento: 8\n",
      "Similitud de coseno: 0.0601929265428846\n",
      "\n",
      "\n",
      "Documento: 9\n",
      "Similitud de coseno: 0.35\n",
      "\n",
      "\n",
      "Documento: 10\n",
      "Similitud de coseno: 0.24514516892273006\n",
      "\n",
      "\n",
      "Documento: 11\n",
      "Similitud de coseno: 0.1687631851389036\n",
      "\n",
      "\n",
      "Documento: 12\n",
      "Similitud de coseno: 0.39167472590032015\n",
      "\n",
      "\n",
      "Documento: 13\n",
      "Similitud de coseno: 0.2906591794880899\n",
      "\n",
      "\n",
      "Documento: 14\n",
      "Similitud de coseno: 0.2195285199793807\n",
      "\n",
      "\n",
      "Documento: 15\n",
      "Similitud de coseno: 0.3076923076923077\n",
      "\n",
      "\n",
      "Documento: 17\n",
      "Similitud de coseno: 0.1898315991504998\n",
      "\n",
      "\n",
      "Documento: 18\n",
      "Similitud de coseno: 0.06622661785325219\n",
      "\n",
      "\n",
      "Documento: 19\n",
      "Similitud de coseno: 0.24659848095803594\n",
      "\n",
      "\n",
      "Documento: 20\n",
      "Similitud de coseno: 0.34156502553198664\n",
      "\n",
      "\n",
      "Documento: 21\n",
      "Similitud de coseno: 0.03747658444979307\n",
      "\n",
      "\n",
      "Documento: 22\n",
      "Similitud de coseno: 0.621997473274912\n",
      "\n",
      "\n",
      "Documento: 25\n",
      "Similitud de coseno: 0.14237369936287486\n",
      "\n",
      "\n",
      "Documento: 26\n",
      "Similitud de coseno: 0.15389675281277312\n",
      "\n",
      "\n",
      "Documento: 27\n",
      "Similitud de coseno: 0.4008071703858348\n",
      "\n",
      "\n",
      "Documento: 28\n",
      "Similitud de coseno: 0.051298917604257706\n",
      "\n",
      "\n",
      "Documento: 29\n",
      "Similitud de coseno: 0.29851115706299675\n",
      "\n",
      "\n",
      "Documento: 31\n",
      "Similitud de coseno: 0.058520573598065284\n",
      "\n",
      "\n",
      "Documento: 32\n",
      "Similitud de coseno: 0.19050019050028574\n",
      "\n",
      "\n",
      "Documento: 33\n",
      "Similitud de coseno: 0.3471825374147068\n",
      "\n",
      "\n",
      "Documento: 34\n",
      "Similitud de coseno: 0.05976143046671968\n",
      "\n",
      "\n",
      "Documento: 35\n",
      "Similitud de coseno: 0.05590169943749474\n",
      "\n",
      "\n",
      "Documento: 36\n",
      "Similitud de coseno: 0.40451991747794525\n",
      "\n",
      "\n",
      "Documento: 37\n",
      "Similitud de coseno: 0.24659848095803594\n",
      "\n",
      "\n",
      "Documento: 38\n",
      "Similitud de coseno: 0.06666666666666667\n",
      "\n",
      "\n",
      "Documento: 39\n",
      "Similitud de coseno: 0.17857142857142858\n",
      "\n",
      "\n",
      "Documento: 43\n",
      "Similitud de coseno: 0.23408229439226114\n",
      "\n",
      "\n",
      "Documento: 44\n",
      "Similitud de coseno: 0.0629940788348712\n",
      "\n",
      "\n",
      "Documento: 46\n",
      "Similitud de coseno: 0.0545544725589981\n",
      "\n",
      "\n",
      "Documento: 49\n",
      "Similitud de coseno: 0.051031036307982884\n",
      "\n",
      "\n",
      "Documento: 50\n",
      "Similitud de coseno: 0.11504474832710555\n",
      "\n",
      "\n",
      "Documento: 51\n",
      "Similitud de coseno: 0.2041241452319315\n",
      "\n",
      "\n",
      "Documento: 52\n",
      "Similitud de coseno: 0.26111648393354675\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_string = \"research on data science and biological analysis\"\n",
    "query_vec = vect_bow.transform([query_string])\n",
    "\n",
    "# Hay que obtener la similitud del coseno entre la query y todos los documentos del conjunto de entrenamiento.\n",
    "# Puedes implementar la similitud desde cero o usar librerías.\n",
    "\n",
    "cos_sim = cosine_similarity(query_vec, X_train_dtm_bow)\n",
    "\n",
    "# Puede que tengas que usar la función np.vstack\n",
    "# Imprimir los documentos recuperados con similitud > 0 (posiblemente necesites usar sort_array_col).\n",
    "\n",
    "indices_similares = np.where(cos_sim > 0)[1]\n",
    "\n",
    "for indice in indices_similares:\n",
    "    print(\"Documento:\", indice)\n",
    "    print(\"Similitud de coseno:\", cos_sim[0, indice])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo TF-IDF\n",
    "\n",
    "Ahora construiremos el modelo TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:27:14.022599100Z",
     "start_time": "2023-09-04T15:27:13.990039500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instanciar el vectorizador\n",
    "# Para TF-IDF quieres usar TfidfVectorizer con los siguientes parámetros: \n",
    "# stop_words='english', ngram_range=(1, 2), max_df=0.95, min_df=2.\n",
    "# Puedes tratar de mejorar el rendimiento cambiando los últimos dos parámetros.\n",
    "vect_tf_idf = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.95, min_df=2)\n",
    "# Ajustar el modelo y luego usarlo para crear una matriz documento-término\n",
    "vect_tf_idf.fit(X_train)\n",
    "X_train_dtm_tf_idf = vect_tf_idf.transform(X_train)\n",
    "\n",
    "# Transformar los datos de prueba (utilizando el vocabulario ajustado) en una matriz documento-término\n",
    "X_test_dtm_tf_idf = vect_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probemos nuestro nuevo modelo con la misma consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:47:49.551535900Z",
     "start_time": "2023-09-04T15:47:49.489605900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento: 15\n",
      "Similitud de coseno: 0.10031373341727577\n",
      "\n",
      "\n",
      "Documento: 26\n",
      "Similitud de coseno: 0.12367193252359335\n",
      "\n",
      "\n",
      "Documento: 29\n",
      "Similitud de coseno: 0.23712539220606624\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_string = \"methodology\"\n",
    "query_vec = vect_bow.transform([query_string])\n",
    "# Puedes reciclar tu código anterior!\n",
    "# Hay que obtener la similitud del coseno entre la query y todos los documentos del conjunto de entrenamiento.\n",
    "# Puedes implementar la similitud desde cero o usar librerías.\n",
    "cos_sim = cosine_similarity(query_vec, X_train_dtm_tf_idf)\n",
    "# Puede que tengas que usar la función np.vstack\n",
    "# Imprimir los documentos recuperados con similitud > 0 (posiblemente necesites usar sort_array_col).\n",
    "\n",
    "indices_similares = np.where(cos_sim > 0)[1]\n",
    "\n",
    "for indice in indices_similares:\n",
    "    print(\"Documento:\", indice)\n",
    "    print(\"Similitud de coseno:\", cos_sim[0, indice])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestro Primer Clasificador\n",
    "\n",
    "Ahora, vamos a saltarnos algunas clases (bueno, muchas clases) y te vamos a obligar a implementar un clasificador Bayesiano. ¿Espera, un qué? Básicamente, queremos un modelo que tome un texto y nos indique su tema. Esto podría hacerse utilizando el clasificador **Naïve Bayes**, que se implementa fácilmente en scikit-learn. Estudiaremos este método más adelante en el curso, pero por ahora lo aplicaremos como una caja negra.\n",
    "\n",
    "Primero, probaremos un clasificador con el Modelo de Bag of Words (BoW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:47:59.542405600Z",
     "start_time": "2023-09-04T15:47:59.525580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.9583333333333334\n",
      "[[13  0  1]\n",
      " [ 0  4  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# La distribución multinomial normalmente requiere recuentos de características enteras.\n",
    "# En este caso, lo usaremos con bag of words que nos entrega la cantidad de ocurrencias de cada palabra.\n",
    "# Instanciar un modelo Naïve Bayes Multinomial\n",
    "nb_bow = MultinomialNB()\n",
    "\n",
    "# Entrenar el modelo usando X_train_dtm con la función fit.\n",
    "\n",
    "nb_bow.fit(X_train_dtm_bow, y_train)\n",
    "\n",
    "# Hacer predicciones de clase para X_test_dtm.\n",
    "y_pred_class = nb_bow.predict(X_test_dtm_bow)\n",
    "\n",
    "# Calcular la precisión de las predicciones de clase utilizando accuracy_score de la librería metrics.\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print(\"Precisión del modelo:\", accuracy)\n",
    "# Imprimir la matriz de confusión (¡veremos qué es esto pronto!) con la función confusion_matrix de la librería metrics.\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probaremos un clasificador con el modelo TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:49:45.140256600Z",
     "start_time": "2023-09-04T15:49:45.082980900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.9166666666666666\n",
      "[[14  0  0]\n",
      " [ 1  3  0]\n",
      " [ 1  0  5]]\n"
     ]
    }
   ],
   "source": [
    "# La distribución multinomial normalmente requiere recuentos de características enteras.\n",
    "# Sin embargo, en la práctica, recuentos fraccionales como tf-idf también pueden funcionar.\n",
    "# Instanciar un modelo Naïve Bayes Multinomial\n",
    "nb_tf_idf = MultinomialNB()\n",
    "\n",
    "# Entrenar el modelo usando X_train_dtm_tf_idf con la función fit.\n",
    "\n",
    "nb_tf_idf.fit(X_train_dtm_tf_idf, y_train)\n",
    "\n",
    "# Hacer predicciones de clase para X_test_dtm_tf_idf.\n",
    "y_pred_class = nb_tf_idf.predict(X_test_dtm_tf_idf)\n",
    "\n",
    "# Calcular la precisión de las predicciones de clase utilizando accuracy_score de la librería metrics.\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print(\"Precisión del modelo:\", accuracy)\n",
    "# Imprimir la matriz de confusión (¡veremos qué es esto pronto!) con la función confusion_matrix de la librería metrics.\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis\n",
    "\n",
    "Entonces, ¿qué modelo es mejor? ¿Coincide esto con los resultados esperados de la clase? Modifica esta celda markdown y agrega tus respuestas a continuación. Considera el rendimiento tanto en la tarea de clasificación como en el modelo de motor de búsqueda. Prueba con consultas adicionales para ver cómo funcionan los modelos. Esta parte, por supuesto, será evaluada.\n",
    "\n",
    "#### Respuesta:\n",
    "- Inserta tu respuesta aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¡Felicitaciones, has completado tu segunda tarea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
